import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st

from modules.load_data import load_data
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

st.header("‚úàÔ∏è Modelo para predi√ß√£o de atrasos de voos")

@st.cache_data
def load_flights_data():
    """Carrega dados de voos, baixando do Kaggle se necess√°rio"""
    try:
        with st.spinner('Verificando dados... Baixando do Kaggle se necess√°rio...'):
            flights = load_data('data', 'flights.csv')
            st.success("‚úÖ Dados carregados com sucesso!")
            return flights
    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados: {str(e)}")
        st.stop()

tab1, tab2, tab3, tab4, tab5 = st.tabs(["üìä An√°lise Explorat√≥ria", "ü§ñ Regress√£o Logistica", "ü§ñ KNN", "ü§ñ Arvore de Decis√£o", "Tentativa de Predi√ß√£o"])

#########################################################
#### MODELO DE PREDICAO DE ATRASOS DE VOO NA CHEGADA ####
#########################################################

with tab1:
    st.subheader("üìñ Descri√ß√£o do Modelo")
    st.write("""
        O modelo visa prever se um voo chegar√° atrasado ao seu destino com base em fatores como:
        - DEP_HOUR: Hora de partida programada (0-23)
        - IS_WEEKEND: Indica se √© fim de semana (1) ou n√£o (0)
        - SEASON: Esta√ß√£o do ano (Winter, Spring, Summer, Fall)
        - TIME_PERIOD: Per√≠odo do dia (Dawn, Morning, Afternoon, Night)
        - HOLIDAY_SEASON: Indica se √© temporada de f√©rias/feriados (1) ou n√£o (0)
    """)

# Criando variavel de target (objetivo)
flights = load_flights_data()
flights['IS_DELAYED'] = (flights['ARRIVAL_DELAY'] >= 15).astype(int)

# Convertendo variaveis categoricas em numericas
airline_encoder = LabelEncoder()
origin_encoder = LabelEncoder()
dest_encoder = LabelEncoder()

# Retirar colunas irrelevantes para o modelo
colunas_para_remover = [
    'TAIL_NUMBER', 'CANCELLATION_REASON', 'AIR_SYSTEM_DELAY',
    'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',
    'WEATHER_DELAY', 'DEPARTURE_TIME', 'WHEELS_OFF', 'WHEELS_ON',
    'TAXI_IN', 'TAXI_OUT', 'ARRIVAL_TIME', 'ARRIVAL_DELAY',
    'ELAPSED_TIME', 'AIR_TIME', 'YEAR', 'FLIGHT_NUMBER',
    'SCHEDULED_DEPARTURE', 'SCHEDULED_ARRIVAL', 'DEPARTURE_DELAY',
    'DIVERTED', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT'
]

# Cria√ß√£o de novas vari√°veis
flights['DEP_HOUR'] = flights['SCHEDULED_DEPARTURE'] // 100
flights['DEP_HOUR'] = flights['DEP_HOUR'].apply(lambda x: min(x, 23)) 
flights['IS_WEEKEND'] = flights['DAY_OF_WEEK'].isin([6, 7]).astype(int)
flights['SEASON'] = pd.cut(flights['MONTH'], bins=[0,3,6,9,12], labels=['Winter','Spring','Summer','Fall'])
flights['TIME_PERIOD'] = pd.cut(flights['DEP_HOUR'], bins=[0,6,12,18,24], labels=['Dawn','Morning','Afternoon','Night'])
flights['HOLIDAY_SEASON'] = flights['MONTH'].isin([7,8,12]).astype(int)

flights['AIRLINE'] = airline_encoder.fit_transform(flights['AIRLINE'])
flights['ORIGIN_ENCODED'] = origin_encoder.fit_transform(flights['ORIGIN_AIRPORT'])
flights['DEST_ENCODED'] = dest_encoder.fit_transform(flights['DESTINATION_AIRPORT'])

# Limpeza dos dados
flights_cleaned = flights.drop(columns=colunas_para_remover, errors='ignore')

# Tratamento de valores ausentes
flights_cleaned = flights_cleaned.fillna(flights_cleaned.median(numeric_only=True))

with tab1:
    #########################################################
    ### ANALISE INICIAL DOS DADOS AP√ìS REMO√á√ÉO DE COLUNAS ###
    #########################################################

    # Colunas que ficamos ap√≥s o tratamento dos dados
    st.subheader("üìä An√°lise do Dataset")
    st.write("### Features Utilizadas")
    flights_exibition = flights_cleaned.drop(columns=['IS_DELAYED'])
    features_info = pd.DataFrame({
        'Feature': flights_exibition.columns.astype(str),
        'Tipo': [str(dtype) for dtype in flights_exibition.dtypes],
        'Valores √önicos': [flights_exibition[col].nunique() for col in flights_exibition.columns],
        'Valores Ausentes (%)': [flights_exibition[col].isna().mean() * 100 for col in flights_exibition.columns]
    })

    st.write("### Estat√≠sticas das Features Num√©ricas")
    numeric_stats = flights_exibition.describe().round(2)
    st.dataframe(numeric_stats)

    st.write("### Informa√ß√µes das Features")
    st.dataframe(features_info.round(2))

    #########################################################
    ############### ESTAT√çSTICAS DESCRITIVAS ###############
    #########################################################
    
    st.subheader("üìà Estat√≠sticas Descritivas Detalhadas")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Distribui√ß√£o da Vari√°vel Target")
        target_dist = flights_cleaned['IS_DELAYED'].value_counts()
        target_percent = flights_cleaned['IS_DELAYED'].value_counts(normalize=True) * 100
        
        target_summary = pd.DataFrame({
            'Categoria': ['N√£o Atrasado', 'Atrasado'],
            'Quantidade': target_dist.values,
            'Percentual (%)': target_percent.values.round(2)
        })
        
        st.dataframe(target_summary)
        st.write(f"**Insight:** {target_percent[0]:.1f}% dos voos n√£o apresentam atrasos significativos (‚â•15 min)")
    
    with col2:
        st.write("### Medidas de Tend√™ncia Central")
        key_features = ['DISTANCE', 'DEP_HOUR', 'MONTH', 'DAY_OF_WEEK']
        
        stats_summary = pd.DataFrame({
            'Feature': key_features,
            'M√©dia': [flights_cleaned[feat].mean() for feat in key_features],
            'Mediana': [flights_cleaned[feat].median() for feat in key_features],
            'Desvio Padr√£o': [flights_cleaned[feat].std() for feat in key_features],
            'Vari√¢ncia': [flights_cleaned[feat].var() for feat in key_features]
        }).round(2)
        
        st.dataframe(stats_summary)

    #########################################################
    ################## HISTOGRAMAS #########################
    #########################################################
    
    st.subheader("üìä Histogramas - Distribui√ß√£o de Atrasos")
    st.write("An√°lise da distribui√ß√£o dos atrasos para entender padr√µes nos dados.")
    
    # Verificar se temos dados de atraso originais
    if 'ARRIVAL_DELAY' in flights.columns:
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("### Distribui√ß√£o de Atrasos na Chegada")
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # Filtrar valores extremos para melhor visualiza√ß√£o
            arrival_delays = flights['ARRIVAL_DELAY'].dropna()
            arrival_delays_filtered = arrival_delays[(arrival_delays >= -50) & (arrival_delays <= 200)]
            
            ax.hist(arrival_delays_filtered, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
            ax.axvline(x=15, color='red', linestyle='--', label='Threshold de Atraso (15 min)')
            ax.set_xlabel('Atraso na Chegada (minutos)')
            ax.set_ylabel('Frequ√™ncia')
            ax.set_title('Distribui√ß√£o dos Atrasos na Chegada')
            ax.legend()
            plt.tight_layout()
            st.pyplot(fig)
        
        with col2:
            st.write("### Distribui√ß√£o de Atrasos na Partida")
            if 'DEPARTURE_DELAY' in flights.columns:
                fig, ax = plt.subplots(figsize=(10, 6))
                
                departure_delays = flights['DEPARTURE_DELAY'].dropna()
                departure_delays_filtered = departure_delays[(departure_delays >= -50) & (departure_delays <= 200)]
                
                ax.hist(departure_delays_filtered, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')
                ax.axvline(x=15, color='red', linestyle='--', label='Threshold de Atraso (15 min)')
                ax.set_xlabel('Atraso na Partida (minutos)')
                ax.set_ylabel('Frequ√™ncia')
                ax.set_title('Distribui√ß√£o dos Atrasos na Partida')
                ax.legend()
                plt.tight_layout()
                st.pyplot(fig)

    #########################################################
    ##################### BOX PLOTS ########################
    #########################################################
    
    st.subheader("üì¶ Box Plots - Identifica√ß√£o de Outliers")
    st.write("An√°lise de outliers nas principais vari√°veis num√©ricas.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Dist√¢ncia dos Voos")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.boxplot(data=flights_cleaned, y='DISTANCE', ax=ax)
        ax.set_title('Box Plot - Dist√¢ncia dos Voos')
        ax.set_ylabel('Dist√¢ncia (milhas)')
        plt.tight_layout()
        st.pyplot(fig)
    
    with col2:
        st.write("### Hora de Partida")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.boxplot(data=flights_cleaned, y='DEP_HOUR', ax=ax)
        ax.set_title('Box Plot - Hora de Partida')
        ax.set_ylabel('Hora (0-23)')
        plt.tight_layout()
        st.pyplot(fig)

    #########################################################
    ################ GR√ÅFICOS DE DISPERS√ÉO #################
    #########################################################
    
    st.subheader("üîç Gr√°ficos de Dispers√£o - Rela√ß√µes entre Vari√°veis")
    st.write("An√°lise das rela√ß√µes entre caracter√≠sticas dos voos e a probabilidade de atraso.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Dist√¢ncia vs Atraso")
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Criar amostra para visualiza√ß√£o (muito dados podem travar)
        sample_data = flights_cleaned.sample(n=min(10000, len(flights_cleaned)), random_state=42)
        
        scatter = ax.scatter(sample_data['DISTANCE'], sample_data['IS_DELAYED'], 
                           alpha=0.5, c=sample_data['IS_DELAYED'], 
                           cmap='coolwarm', s=10)
        ax.set_xlabel('Dist√¢ncia (milhas)')
        ax.set_ylabel('Atraso (0=N√£o, 1=Sim)')
        ax.set_title('Rela√ß√£o: Dist√¢ncia vs Atraso')
        plt.colorbar(scatter)
        plt.tight_layout()
        st.pyplot(fig)
    
    with col2:
        st.write("### Hora de Partida vs Atraso")
        fig, ax = plt.subplots(figsize=(10, 6))
        
        scatter = ax.scatter(sample_data['DEP_HOUR'], sample_data['IS_DELAYED'], 
                           alpha=0.5, c=sample_data['IS_DELAYED'], 
                           cmap='coolwarm', s=10)
        ax.set_xlabel('Hora de Partida')
        ax.set_ylabel('Atraso (0=N√£o, 1=Sim)')
        ax.set_title('Rela√ß√£o: Hora de Partida vs Atraso')
        plt.colorbar(scatter)
        plt.tight_layout()
        st.pyplot(fig)

    #########################################################
    ############### AN√ÅLISES POR CATEGORIA #################
    #########################################################
    
    st.subheader("üìã An√°lises Categ√≥ricas")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Taxa de Atraso por M√™s")
        monthly_delays = flights_cleaned.groupby('MONTH')['IS_DELAYED'].agg(['mean', 'count']).round(3)
        monthly_delays.columns = ['Taxa_Atraso', 'Total_Voos']
        monthly_delays = monthly_delays.reset_index()
        
        fig, ax = plt.subplots(figsize=(10, 6))
        bars = ax.bar(monthly_delays['MONTH'], monthly_delays['Taxa_Atraso'], 
                     color='lightblue', alpha=0.7, edgecolor='black')
        ax.set_xlabel('M√™s')
        ax.set_ylabel('Taxa de Atraso')
        ax.set_title('Taxa de Atraso por M√™s do Ano')
        ax.set_xticks(range(1, 13))
        
        # Adicionar valores nas barras
        for bar, rate in zip(bars, monthly_delays['Taxa_Atraso']):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
                   f'{rate:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        st.pyplot(fig)
    
    with col2:
        st.write("### Taxa de Atraso por Dia da Semana")
        weekly_delays = flights_cleaned.groupby('DAY_OF_WEEK')['IS_DELAYED'].agg(['mean', 'count']).round(3)
        weekly_delays.columns = ['Taxa_Atraso', 'Total_Voos']
        weekly_delays = weekly_delays.reset_index()
        
        fig, ax = plt.subplots(figsize=(10, 6))
        bars = ax.bar(weekly_delays['DAY_OF_WEEK'], weekly_delays['Taxa_Atraso'], 
                     color='lightgreen', alpha=0.7, edgecolor='black')
        ax.set_xlabel('Dia da Semana (1=Segunda, 7=Domingo)')
        ax.set_ylabel('Taxa de Atraso')
        ax.set_title('Taxa de Atraso por Dia da Semana')
        ax.set_xticks(range(1, 8))
        
        # Adicionar valores nas barras
        for bar, rate in zip(bars, weekly_delays['Taxa_Atraso']):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005, 
                   f'{rate:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        st.pyplot(fig)

    #########################################################
    ########## HEATMAP DE CORRELA√á√ÉO ENTRE FEATURES #########
    #########################################################
    
    st.subheader("üî• Matriz de Correla√ß√£o das Features")
    st.write("""
        Este heatmap mostra a correla√ß√£o entre todas as features num√©ricas ap√≥s o processamento.
        **Cores mais intensas** indicam correla√ß√µes mais fortes (positivas ou negativas).
    """)
    
    # Selecionar apenas features num√©ricas para correla√ß√£o
    numeric_features_for_corr = flights_cleaned.select_dtypes(include=[np.number]).columns.tolist()
    
    # Calcular matriz de correla√ß√£o
    correlation_matrix = flights_cleaned[numeric_features_for_corr].corr()
    
    # Criar o heatmap
    fig, ax = plt.subplots(figsize=(14, 10))
    
    # M√°scara para mostrar apenas metade da matriz (mais limpo)
    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
    
    sns.heatmap(
        correlation_matrix,
        mask=mask,
        annot=True,
        fmt='.2f',
        cmap='RdBu_r',
        center=0,
        square=True,
        linewidths=0.5,
        cbar_kws={"shrink": .8},
        ax=ax
    )
    
    plt.title('Matriz de Correla√ß√£o entre Features Num√©ricas', fontsize=16, pad=20)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    plt.tight_layout()
    st.pyplot(fig)
    
    #########################################################
    ############## AN√ÅLISE DE CORRELA√á√ÉO ###################
    #########################################################
    
    st.subheader("üéØ An√°lise de Correla√ß√£o com a Vari√°vel Target")
    
    target_correlations = correlation_matrix['IS_DELAYED'].abs().sort_values(ascending=False)
    target_correlations = target_correlations.drop('IS_DELAYED')  # Remover self-correlation
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Top 10 Correla√ß√µes Mais Fortes:")
        top_correlations = pd.DataFrame({
            'Feature': target_correlations.head(10).index,
            'Correla√ß√£o Absoluta': target_correlations.head(10).values,
            'Correla√ß√£o Original': [correlation_matrix.loc[feat, 'IS_DELAYED'] for feat in target_correlations.head(10).index]
        }).round(3)
        
        st.dataframe(top_correlations)
        
        # Insights autom√°ticos
        st.write("### üí° Insights das Correla√ß√µes:")
        strongest_positive = correlation_matrix['IS_DELAYED'][correlation_matrix['IS_DELAYED'] > 0].nlargest(3)
        strongest_negative = correlation_matrix['IS_DELAYED'][correlation_matrix['IS_DELAYED'] < 0].nsmallest(3)
        
        if len(strongest_positive) > 0:
            st.write(f"**Correla√ß√µes Positivas Moderadas:** {', '.join(strongest_positive.index[:3])}")
        if len(strongest_negative) > 0:
            st.write(f"**Correla√ß√µes Negativas:** {', '.join(strongest_negative.index[:3])}")
        
        # Confirmar o insight do relat√≥rio
        key_correlations = ['DISTANCE', 'DEP_HOUR', 'MONTH']
        available_correlations = [feat for feat in key_correlations if feat in correlation_matrix.index]
        
        if available_correlations:
            st.write("### üìã Correla√ß√µes Identificadas (Relat√≥rio):")
            for feat in available_correlations:
                corr_val = correlation_matrix.loc[feat, 'IS_DELAYED']
                st.write(f"- **{feat}**: {corr_val:.3f} ({'moderada' if abs(corr_val) > 0.1 else 'fraca'})")
    
    with col2:
        st.write("### Visualiza√ß√£o das Top 10 Correla√ß√µes:")
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Pegar correla√ß√£o original (com sinal)
        top_corr_with_sign = [correlation_matrix.loc[feat, 'IS_DELAYED'] for feat in target_correlations.head(10).index]
        
        colors = ['red' if x < 0 else 'blue' for x in top_corr_with_sign]
        
        bars = ax.barh(range(len(top_corr_with_sign)), top_corr_with_sign, color=colors, alpha=0.7)
        ax.set_yticks(range(len(top_corr_with_sign)))
        ax.set_yticklabels(target_correlations.head(10).index)
        ax.set_xlabel('Correla√ß√£o com IS_DELAYED')
        ax.set_title('Top 10 Features por Correla√ß√£o com Target')
        ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
        
        # Adicionar valores nas barras
        for i, (bar, val) in enumerate(zip(bars, top_corr_with_sign)):
            ax.text(val + (0.01 if val >= 0 else -0.01), i, f'{val:.3f}', 
                   va='center', ha='left' if val >= 0 else 'right')
        
        plt.tight_layout()
        st.pyplot(fig)

with tab2:
    #########################################################
    ###### TREINAMENTO DO MODELO DE REGRESSAO LOGISTICA #####
    #########################################################

    st.subheader("ü§ñ Modelo utilizando regress√£o log√≠stica")
    st.markdown("""
        ### Por que Regress√£o Log√≠stica?
        
        - **Simplicidade**: Modelo linear de f√°cil interpreta√ß√£o
        - **Efici√™ncia**: Bom desempenho em classifica√ß√£o bin√°ria
        - **Rapidez**: Treinamento r√°pido mesmo com grandes volumes de dados
        - **Probabilidades**: Fornece probabilidades de atraso
        
        ### Como funciona?
        O modelo analisa as caracter√≠sticas do voo (hor√°rio, dist√¢ncia, aeroportos, etc.) 
        e calcula a probabilidade dele atrasar. Se essa probabilidade for maior que 50%, 
        o voo √© classificado como "prov√°vel atraso".
        
        ### Vantagens para Previs√£o de Atrasos:
        - Captura rela√ß√µes lineares entre as features
        - Menos propenso a overfitting que modelos mais complexos
        - Resultados facilmente interpret√°veis
        - Boa baseline para compara√ß√£o com outros modelos
    """)

# Separa√ß√£o das features (X) e target (y)            
X = flights_cleaned.drop(columns=['IS_DELAYED'])
y = flights_cleaned['IS_DELAYED']

# Defini√ß√£o das features categ√≥ricas e num√©ricas para preprocessamento
categorical_features = ['SEASON', 'TIME_PERIOD']
numeric_features = [
    'AIRLINE', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'DEP_HOUR', 
    'DISTANCE', 'CANCELLED', 'ORIGIN_ENCODED', 
    'DEST_ENCODED', 'IS_WEEKEND'
    ]

# Cria√ß√£o do preprocessador para tratamento das features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)
    ])

# Divis√£o dos dados em conjuntos de treino (80%) e valida√ß√£o (20%)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Aplica√ß√£o do preprocessamento
X_train = preprocessor.fit_transform(X_train)
X_val = preprocessor.transform(X_val)

with tab2:
    # Treinamento do modelo de Regress√£o Log√≠stica
    with st.spinner('Treinando o modelo de Regress√£o Log√≠stica...'):
        sample_size = int(0.2 * len(X_train))
        indices = np.random.choice(len(X_train), sample_size, replace=False)
        X_train_sample = X_train[indices]
        y_train_sample = y_train.iloc[indices]

        # Treinar com amostra reduzida
        model = LogisticRegression(
            random_state=42,
            max_iter=1000,
            solver='saga',
            n_jobs=-1
        )
        model.fit(X_train_sample, y_train_sample)
        y_pred = model.predict(X_val)

    st.subheader("üìä Perfomance do modelo sem balanceamento de classes")

    col1, col2 = st.columns(2)

    with col1:
        report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)
        df_report = pd.DataFrame(report).transpose()
        
        # Formatando a tabela
        df_report = df_report.round(3)  
        df_report = df_report.drop('support', axis=1)  
        
        # Renomeando os √≠ndices para mais leg√≠veis
        df_report.index = df_report.index.map({
            '0': 'N√£o Atrasado',
            '1': 'Atrasado',
            'accuracy': 'Acur√°cia',
            'macro avg': 'M√©dia Macro',
            'weighted avg': 'M√©dia Ponderada'
        })
        
        st.write("### Classifica√ß√£o do Modelo:")
        st.dataframe(df_report.style.format("{:.2%}"))

    with col2:
        st.subheader("üéØ Matriz de Confus√£o")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            confusion_matrix(y_val, y_pred),
            annot=True,
            fmt="d",
            cmap="Blues",
            ax=ax
        )
        plt.title("Logistic Regression - Confusion Matrix")
        plt.xlabel("Predicted")
        plt.ylabel("Actual")
        st.pyplot(fig)

    # Balanceamento de classes com SMOTE
    with st.spinner('Aplicando balanceamento de classes...'):
        smote = SMOTE(random_state=42)
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_sample, y_train_sample)

        # Treinamento do modelo com dados balanceados
        model_balanced = LogisticRegression(
            random_state=42,
            max_iter=1000,
            solver='saga',
            n_jobs=-1
        )
        model_balanced.fit(X_train_balanced, y_train_balanced)
        
        # Previs√µes com threshold ajustado
        y_pred_proba = model_balanced.predict_proba(X_val)
        y_pred_balanced = (y_pred_proba[:, 1] > 0.3).astype(int)

    st.subheader("üìä Performance do Modelo Balanceado")

    # Exibi√ß√£o dos resultados
    col1, col2 = st.columns(2)

    with col1:
        report = classification_report(y_val, y_pred_balanced, output_dict=True, zero_division=0)
        df_report = pd.DataFrame(report).transpose()
        
        # Formatando a tabela
        df_report = df_report.round(3)  
        df_report = df_report.drop('support', axis=1)  
        
        # Renomeando os √≠ndices
        df_report.index = df_report.index.map({
            '0': 'N√£o Atrasado',
            '1': 'Atrasado',
            'accuracy': 'Acur√°cia',
            'macro avg': 'M√©dia Macro',
            'weighted avg': 'M√©dia Ponderada'
        })
        
        st.write("### Classifica√ß√£o do Modelo:")
        st.dataframe(df_report.style.format("{:.2%}"))

    with col2:
        st.subheader("üéØ Matriz de Confus√£o")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            confusion_matrix(y_val, y_pred_balanced),
            annot=True,
            fmt="d",
            cmap="Blues",
            ax=ax
        )
        plt.title("Regress√£o Log√≠stica Balanceada")
        plt.xlabel("Previsto")
        plt.ylabel("Real")
        st.pyplot(fig)

with tab3:
    #########################################################
    ############### TREINAMENTO DO MODELO KNN ###############
    #########################################################

    st.subheader("üéØ KNN Model")
    st.markdown("""
        ### Por que KNN?
        
        - **Simplicidade**: Modelo intuitivo baseado em similaridade
        - **N√£o-param√©trico**: N√£o assume distribui√ß√£o dos dados
        - **Versatilidade**: Eficaz em padr√µes locais
        - **Adaptabilidade**: Ajusta-se naturalmente √† complexidade dos dados
        
        ### Como funciona?
        O modelo analisa os K voos mais similares ao voo em quest√£o e decide
        com base na maioria. Por exemplo:
        - Se entre os 5 voos mais similares, 3 atrasaram
        - Ent√£o o modelo prev√™ que este voo tamb√©m atrasar√°
        
        ### Vantagens para Previs√£o de Atrasos:
        - Captura padr√µes locais de atrasos
        - Considera similaridade entre rotas e condi√ß√µes
        - Adapta-se a diferentes regi√µes do espa√ßo de features
        - Decis√µes baseadas em casos reais similares
    """)

    with st.spinner('Treinando modelo KNN...'):
        y_train_np = y_train.to_numpy()
        
        sample_size = int(0.2 * len(X_train))
        indices = np.random.choice(len(X_train), sample_size, replace=False)
        X_train_sample = X_train[indices]
        y_train_sample = y_train_np[indices]

        knn_param_grid = {
            'n_neighbors': [3, 5],
            'weights': ['uniform'],
            'p': [2]  
        }
        
        knn_grid_search = GridSearchCV(
            KNeighborsClassifier(n_jobs=-1),
            knn_param_grid,
            cv=3,
            scoring={
                'recall': 'recall',
                'precision': 'precision',
                'f1': 'f1'
            },
            refit='recall',
            n_jobs=-1,
            verbose=2
        )
        
        try:
            # 5. Treinamento com dados reduzidos
            knn_grid_search.fit(X_train_sample, y_train_sample)
            knn_model = knn_grid_search.best_estimator_
            knn_pred = knn_model.predict(X_val)
            
        except Exception as e:
            st.error(f"Erro no treinamento: {str(e)}")
            st.stop()

        col1, col2 = st.columns(2)

        with col1:
            # Relat√≥rio de classifica√ß√£o
            report = classification_report(y_val, knn_pred, output_dict=True, zero_division=0)
            df_report = pd.DataFrame(report).transpose()
            
            # Formata√ß√£o da tabela
            df_report = df_report.round(3)
            df_report = df_report.drop('support', axis=1)
            
            # Renomeando √≠ndices
            df_report.index = df_report.index.map({
                '0': 'N√£o Atrasado',
                '1': 'Atrasado',
                'accuracy': 'Acur√°cia',
                'macro avg': 'M√©dia Macro',
                'weighted avg': 'M√©dia Ponderada'
            })
            
            st.write("### Classifica√ß√£o do Modelo:")
            st.dataframe(df_report.style.format("{:.2%}"))
            
            # Melhores par√¢metros
            st.write("### Melhores Par√¢metros:")
            st.json(knn_grid_search.best_params_)

        with col2:
            # Matriz de confus√£o
            st.subheader("üéØ Matriz de Confus√£o")
            fig, ax = plt.subplots(figsize=(8, 6))
            sns.heatmap(
                confusion_matrix(y_val, knn_pred),
                annot=True,
                fmt="d",
                cmap="Purples",
                ax=ax
            )
            plt.title("KNN - Matriz de Confus√£o")
            plt.xlabel("Previsto")
            plt.ylabel("Real")
            st.pyplot(fig)

with tab4:
    #########################################################
    ###### TREINAMENTO DO MODELO DE ARVORE DE DECISSAO ######
    #########################################################

    st.subheader("üå≥ Modelo de √°rvore de decis√£o")
    st.markdown("""
        ### Por que √Årvore de Decis√£o?
        
        - **Interpretabilidade**: F√°cil visualiza√ß√£o das regras de decis√£o
        - **N√£o-linear**: Captura rela√ß√µes complexas entre features
        - **Robustez**: Lida bem com diferentes tipos de features
        - **Hierarquia**: Identifica features mais importantes
                
        ### Como funciona?
        O modelo cria uma estrutura em √°rvore onde cada n√≥ representa uma decis√£o 
        baseada em uma feature espec√≠fica. Por exemplo:
        - Se a hora de partida < 6h, vai para um caminho
        - Se a dist√¢ncia > 1000 milhas, vai para outro
        - E assim sucessivamente at√© chegar a uma previs√£o final

        ### Vantagens para Previs√£o de Atrasos:
        - Captura naturalmente padr√µes sazonais e hor√°rios
        - Identifica combina√ß√µes cr√≠ticas de fatores que levam a atrasos
        - Permite visualizar o processo de decis√£o
        - Lida bem com features num√©ricas e categ√≥ricas
        - Funciona mesmo com dados n√£o balanceados
    """)

    with st.spinner('Treinando a √°rvore de decis√£o...'):
        # Convert to numpy array and sample data
        y_train_np = y_train.to_numpy()
        
        sample_size = int(0.2 * len(X_train))
        indices = np.random.choice(len(X_train), sample_size, replace=False)
        X_train_sample = X_train[indices]
        y_train_sample = y_train_np[indices]
        
        param_grid = {
            'max_depth': [5, 10],
            'min_samples_split': [50, 100],
            'min_samples_leaf': [20, 30],
            'criterion': ['gini'],
            'class_weight': [None, 'balanced']
        }

        # Criar e executar GridSearchCV com a amostra
        grid_search = GridSearchCV(
            DecisionTreeClassifier(random_state=42),
            param_grid,
            cv=3,
            scoring={
                'accuracy': 'accuracy',
                'recall': 'recall',
                'precision': 'precision',
                'f1': 'f1'
            },
            refit='recall',  
            n_jobs=-1,
            verbose=1
        )
        
        try:
            # Apply SMOTE on the sample instead of full dataset
            smote = SMOTE(random_state=42)
            X_train_balanced, y_train_balanced = smote.fit_resample(X_train_sample, y_train_sample)
            grid_search.fit(X_train_balanced, y_train_balanced)
            
            dt_model = grid_search.best_estimator_
            dt_pred = dt_model.predict(X_val)
            dt_pred_proba = dt_model.predict_proba(X_val)
            
        except Exception as e:
            st.error(f"Erro no treinamento: {str(e)}")
            st.stop()

    # Mostrar performance do Decision Tree
    col1, col2 = st.columns(2)

    with col1:
        # M√©tricas detalhadas
        report = classification_report(y_val, dt_pred, output_dict=True, zero_division=0)
        df_report = pd.DataFrame(report).transpose()
        df_report = df_report.round(3)
        df_report = df_report.drop('support', axis=1)
        
        df_report.index = df_report.index.map({
            '0': 'N√£o Atrasado',
            '1': 'Atrasado',
            'accuracy': 'Acur√°cia',
            'macro avg': 'M√©dia Macro',
            'weighted avg': 'M√©dia Ponderada'
        })
        
        st.write("### Classifica√ß√£o do Modelo:")
        st.dataframe(df_report.style.format("{:.2%}"))
        
        # Melhores par√¢metros
        st.write("### Melhores Par√¢metros:")
        st.json(grid_search.best_params_)

    with col2:
        # Matriz de confus√£o
        st.subheader("üéØ Matriz de Confus√£o")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            confusion_matrix(y_val, dt_pred),
            annot=True,
            fmt="d",
            cmap="Greens",
            ax=ax
        )
        plt.title("√Årvore de Decis√£o - Matriz de Confus√£o")
        plt.xlabel("Previsto")
        plt.ylabel("Real")
        st.pyplot(fig)
        
        # Feature Importance
        st.subheader("üîç Import√¢ncia das Features")
        feature_names = (
            numeric_features + 
            [f"{feat}_{val}" for feat, vals in 
            zip(categorical_features, 
                preprocessor.named_transformers_['cat'].categories_) 
            for val in vals[1:]]  # Skip first category due to drop='first'
        )
        
        feature_importance = pd.DataFrame({
            'Feature': feature_names,
            'Importance': dt_model.feature_importances_
        }).sort_values('Importance', ascending=False)
        
        # Plot top 15 most important features
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(
            data=feature_importance.head(15),
            x='Importance',
            y='Feature'
        )
        plt.title("Top 15 Features mais Importantes")
        plt.tight_layout()
        st.pyplot(fig)

with tab5:
    #########################################################
    ################## TENTATIVA DE PREVISAO ################
    #########################################################

    st.subheader("‚úàÔ∏è Predictor de Atrasos de Voos")

    with st.form("flight_predictor"):
        col1, col2 = st.columns(2)
        
        with col1:
            month = st.number_input("M√™s", min_value=1, max_value=12, value=6)
            day = st.number_input("Dia", min_value=1, max_value=31, value=15)
            day_of_week = st.number_input("Dia da Semana (1-7)", min_value=1, max_value=7, value=1)
            dep_hour = st.number_input("Hora de Partida (0-23)", min_value=0, max_value=23, value=14)
            distance = st.number_input("Dist√¢ncia (milhas)", min_value=0, max_value=5000, value=2475)
        
        with col2:
            airline = st.selectbox("Companhia A√©rea", options=sorted(flights['AIRLINE'].unique()))
            origin = st.selectbox("Aeroporto de Origem", options=sorted(flights['ORIGIN_AIRPORT'].unique()))
            destination = st.selectbox("Aeroporto de Destino", options=sorted(flights['DESTINATION_AIRPORT'].unique()))
            cancelled = st.checkbox("Voo Cancelado")
        
        # Adicionar campos para as novas features
        is_weekend = 1 if day_of_week in [6, 7] else 0
        season = pd.cut([month], bins=[0,3,6,9,12], labels=['Winter','Spring','Summer','Fall'])[0]
        time_period = pd.cut([dep_hour], bins=[0,6,12,18,24], labels=['Dawn','Morning','Afternoon','Night'])[0]
        holiday_season = 1 if month in [7,8,12] else 0
        
        model_choice = st.radio(
            "Escolha o Modelo",
            ["√Årvore de Decis√£o", "KNN"]
        )

        submitted = st.form_submit_button("Prever Atraso")

    if submitted:
        # Criar DataFrame com todas as features necess√°rias
        input_data = pd.DataFrame([{
            'AIRLINE': airline_encoder.transform([airline])[0],
            'MONTH': month,
            'DAY': day,
            'DAY_OF_WEEK': day_of_week,
            'DEP_HOUR': dep_hour,
            'DISTANCE': distance,
            'CANCELLED': int(cancelled),
            'ORIGIN_ENCODED': origin_encoder.transform([origin])[0],
            'DEST_ENCODED': dest_encoder.transform([destination])[0],
            'IS_WEEKEND': is_weekend,
            'SEASON': season,
            'TIME_PERIOD': time_period,
            'HOLIDAY_SEASON': holiday_season
        }])

        # Preprocessar dados de entrada
        input_processed = preprocessor.transform(input_data)

        # Fazer predi√ß√£o com o modelo escolhido
        if model_choice == "√Årvore de Decis√£o":
            prediction = dt_model.predict(input_processed)[0]
            probability = dt_model.predict_proba(input_processed)[0][1]
        else:  # KNN
            prediction = knn_model.predict(input_processed)[0]
            probability = knn_model.predict_proba(input_processed)[0][1]

        # Mostrar resultados
        result = 'üü• Atrasado' if prediction == 1 else 'üü© No Hor√°rio'
        
        st.markdown(f"### Previs√£o: {result}")
        st.markdown(f"### Probabilidade de Atraso: {probability:.2%}")
        
        if prediction == 1:
            st.warning("Este voo provavelmente ir√° atrasar!")
        else:
            st.success("Este voo provavelmente chegar√° no hor√°rio!")

        # Se for √°rvore de decis√£o, mostrar import√¢ncia das features
        if model_choice == "√Årvore de Decis√£o":
            st.subheader("üîç Import√¢ncia das Features para esta Previs√£o")
            feature_names = (
                numeric_features + 
                [f"{feat}_{val}" for feat, vals in 
                zip(categorical_features, 
                    preprocessor.named_transformers_['cat'].categories_) 
                for val in vals[1:]]
            )
            
            importance = pd.DataFrame({
                'Feature': feature_names,
                'Importance': dt_model.feature_importances_
            }).sort_values('Importance', ascending=False).head(5)
            
            fig, ax = plt.subplots(figsize=(10, 4))
            sns.barplot(data=importance, x='Importance', y='Feature')
            plt.title("Top 5 Features Mais Importantes")
            plt.tight_layout()
            st.pyplot(fig)