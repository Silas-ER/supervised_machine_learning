import datetime
import pandas as pd
import numpy as np
import seaborn as sns
import lightgbm as lgb
from lightgbm import LGBMClassifier
import matplotlib.pyplot as plt
import streamlit as st
import xgboost as xgb

from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from imblearn.over_sampling import SMOTE

#########################################################
#### MODELO DE PREDICAO DE ATRASOS DE VOO NA CHEGADA ####
#########################################################

st.header("‚úàÔ∏è Modelo para predi√ß√£o de atrasos de voos")
st.subheader("üìñ Descri√ß√£o do Modelo")
st.write("""
    O modelo visa prever se um voo chegar√° atrasado ao seu destino com base em fatores como:
    - DEP_HOUR: Hora de partida programada (0-23)
    - IS_WEEKEND: Indica se √© fim de semana (1) ou n√£o (0)
    - SEASON: Esta√ß√£o do ano (Winter, Spring, Summer, Fall)
    - TIME_PERIOD: Per√≠odo do dia (Dawn, Morning, Afternoon, Night)
    - HOLIDAY_SEASON: Indica se √© temporada de f√©rias/feriados (1) ou n√£o (0)
""")

# Criando variavel de target (objetivo)
flights = pd.read_csv('data/flights.csv', low_memory=False)
flights['IS_DELAYED'] = (flights['ARRIVAL_DELAY'] >= 15).astype(int)

# Convertendo variaveis categoricas em numericas
airline_encoder = LabelEncoder()
origin_encoder = LabelEncoder()
dest_encoder = LabelEncoder()

# Retirar colunas irrelevantes para o modelo
colunas_para_remover = [
    'TAIL_NUMBER', 'CANCELLATION_REASON', 'AIR_SYSTEM_DELAY',
    'SECURITY_DELAY', 'AIRLINE_DELAY', 'LATE_AIRCRAFT_DELAY',
    'WEATHER_DELAY', 'DEPARTURE_TIME', 'WHEELS_OFF', 'WHEELS_ON',
    'TAXI_IN', 'TAXI_OUT', 'ARRIVAL_TIME', 'ARRIVAL_DELAY',
    'ELAPSED_TIME', 'AIR_TIME', 'YEAR', 'FLIGHT_NUMBER',
    'SCHEDULED_DEPARTURE', 'SCHEDULED_ARRIVAL', 'DEPARTURE_DELAY',
    'DIVERTED', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT'
]

# Cria√ß√£o de novas vari√°veis
flights['DEP_HOUR'] = flights['SCHEDULED_DEPARTURE'] // 100
flights['DEP_HOUR'] = flights['DEP_HOUR'].apply(lambda x: min(x, 23)) 
flights['IS_WEEKEND'] = flights['DAY_OF_WEEK'].isin([6, 7]).astype(int)
flights['SEASON'] = pd.cut(flights['MONTH'], bins=[0,3,6,9,12], labels=['Winter','Spring','Summer','Fall'])
flights['TIME_PERIOD'] = pd.cut(flights['DEP_HOUR'], bins=[0,6,12,18,24], labels=['Dawn','Morning','Afternoon','Night'])
flights['HOLIDAY_SEASON'] = flights['MONTH'].isin([7,8,12]).astype(int)

flights['AIRLINE'] = airline_encoder.fit_transform(flights['AIRLINE'])
flights['ORIGIN_ENCODED'] = origin_encoder.fit_transform(flights['ORIGIN_AIRPORT'])
flights['DEST_ENCODED'] = dest_encoder.fit_transform(flights['DESTINATION_AIRPORT'])

# Limpeza dos dados
flights_cleaned = flights.drop(columns=colunas_para_remover, errors='ignore')

# Tratamento de valores ausentes
flights_cleaned = flights_cleaned.fillna(flights_cleaned.median(numeric_only=True))

#########################################################
### ANALISE INICIAL DOS DADOS AP√ìS REMO√á√ÉO DE COLUNAS ###
#########################################################

# Colunas que ficamos ap√≥s o tratamento dos dados
st.subheader("üìä An√°lise do Dataset")
st.write("### Features Utilizadas")
flights_exibition = flights_cleaned.drop(columns=['IS_DELAYED'])
features_info = pd.DataFrame({
    'Feature': flights_exibition.columns.astype(str),
    'Tipo': [str(dtype) for dtype in flights_exibition.dtypes],
    'Valores √önicos': [flights_exibition[col].nunique() for col in flights_exibition.columns],
    'Valores Ausentes (%)': [flights_exibition[col].isna().mean() * 100 for col in flights_exibition.columns]
})

st.write("### Estat√≠sticas das Features Num√©ricas")
numeric_stats = flights_exibition.describe().round(2)
st.dataframe(numeric_stats)

st.write("### Informa√ß√µes das Features")
st.dataframe(features_info.round(2))

st.write("### Primeiras linhas do Dataset")
st.dataframe(flights_exibition.head(5))

#########################################################
###### TREINAMENTO DO MODELO DE REGRESSAO LOGISTICA #####
#########################################################

st.subheader("ü§ñ Modelo utilizando regress√£o log√≠stica")
st.markdown("""
    ### Por que Regress√£o Log√≠stica?
    
    - **Simplicidade**: Modelo linear de f√°cil interpreta√ß√£o
    - **Efici√™ncia**: Bom desempenho em classifica√ß√£o bin√°ria
    - **Rapidez**: Treinamento r√°pido mesmo com grandes volumes de dados
    - **Probabilidades**: Fornece probabilidades de atraso
    
    ### Como funciona?
    O modelo analisa as caracter√≠sticas do voo (hor√°rio, dist√¢ncia, aeroportos, etc.) 
    e calcula a probabilidade dele atrasar. Se essa probabilidade for maior que 50%, 
    o voo √© classificado como "prov√°vel atraso".
    
    ### Vantagens para Previs√£o de Atrasos:
    - Captura rela√ß√µes lineares entre as features
    - Menos propenso a overfitting que modelos mais complexos
    - Resultados facilmente interpret√°veis
    - Boa baseline para compara√ß√£o com outros modelos
""")

# Separa√ß√£o das features (X) e target (y)            
X = flights_cleaned.drop(columns=['IS_DELAYED'])
y = flights_cleaned['IS_DELAYED']

# Defini√ß√£o das features categ√≥ricas e num√©ricas para preprocessamento
categorical_features = ['SEASON', 'TIME_PERIOD']
numeric_features = [
    'AIRLINE', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'DEP_HOUR', 
    'DISTANCE', 'CANCELLED', 'ORIGIN_ENCODED', 
    'DEST_ENCODED', 'IS_WEEKEND'
    ]

# Cria√ß√£o do preprocessador para tratamento das features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)
    ])

# Divis√£o dos dados em conjuntos de treino (80%) e valida√ß√£o (20%)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Aplica√ß√£o do preprocessamento
X_train = preprocessor.fit_transform(X_train)
X_val = preprocessor.transform(X_val)

# Treinamento do modelo de Regress√£o Log√≠stica
with st.spinner('Treinando o modelo de Regress√£o Log√≠stica...'):
    model = LogisticRegression(random_state=42, max_iter=1000, solver='saga', n_jobs=-1)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)

st.subheader("üìä Perfomance do modelo sem balanceamento de classes")

col1, col2 = st.columns(2)

with col1:
    report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)
    df_report = pd.DataFrame(report).transpose()
    
    # Formatando a tabela
    df_report = df_report.round(3)  
    df_report = df_report.drop('support', axis=1)  
    
    # Renomeando os √≠ndices para mais leg√≠veis
    df_report.index = df_report.index.map({
        '0': 'N√£o Atrasado',
        '1': 'Atrasado',
        'accuracy': 'Acur√°cia',
        'macro avg': 'M√©dia Macro',
        'weighted avg': 'M√©dia Ponderada'
    })
    
    st.write("### Classifica√ß√£o do Modelo:")
    st.dataframe(df_report.style.format("{:.2%}"))

with col2:
    st.subheader("üéØ Matriz de Confus√£o")
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(
        confusion_matrix(y_val, y_pred),
        annot=True,
        fmt="d",
        cmap="Blues",
        ax=ax
    )
    plt.title("Logistic Regression - Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    st.pyplot(fig)

# Balanceamento de classes com SMOTE
with st.spinner('Aplicando balanceamento de classes...'):
    smote = SMOTE(random_state=42)
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

    # Treinamento do modelo com dados balanceados
    model_balanced = LogisticRegression(
        random_state=42,
        max_iter=1000,
        solver='saga',
        n_jobs=-1
    )
    model_balanced.fit(X_train_balanced, y_train_balanced)
    
    # Previs√µes com threshold ajustado
    y_pred_proba = model_balanced.predict_proba(X_val)
    y_pred_balanced = (y_pred_proba[:, 1] > 0.3).astype(int)

st.subheader("üìä Performance do Modelo Balanceado")

# Exibi√ß√£o dos resultados
col1, col2 = st.columns(2)

with col1:
    report = classification_report(y_val, y_pred_balanced, output_dict=True, zero_division=0)
    df_report = pd.DataFrame(report).transpose()
    
    # Formatando a tabela
    df_report = df_report.round(3)  
    df_report = df_report.drop('support', axis=1)  
    
    # Renomeando os √≠ndices
    df_report.index = df_report.index.map({
        '0': 'N√£o Atrasado',
        '1': 'Atrasado',
        'accuracy': 'Acur√°cia',
        'macro avg': 'M√©dia Macro',
        'weighted avg': 'M√©dia Ponderada'
    })
    
    st.write("### Classifica√ß√£o do Modelo:")
    st.dataframe(df_report.style.format("{:.2%}"))

with col2:
    st.subheader("üéØ Matriz de Confus√£o")
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(
        confusion_matrix(y_val, y_pred_balanced),
        annot=True,
        fmt="d",
        cmap="Blues",
        ax=ax
    )
    plt.title("Regress√£o Log√≠stica Balanceada")
    plt.xlabel("Previsto")
    plt.ylabel("Real")
    st.pyplot(fig)

#########################################################
############### TREINAMENTO DO MODELO KNN ###############
#########################################################

st.subheader("üéØ KNN Model")
st.markdown("""
    ### Por que KNN?
    
    - **Simplicidade**: Modelo intuitivo baseado em similaridade
    - **N√£o-param√©trico**: N√£o assume distribui√ß√£o dos dados
    - **Versatilidade**: Eficaz em padr√µes locais
    - **Adaptabilidade**: Ajusta-se naturalmente √† complexidade dos dados
    
    ### Como funciona?
    O modelo analisa os K voos mais similares ao voo em quest√£o e decide
    com base na maioria. Por exemplo:
    - Se entre os 5 voos mais similares, 3 atrasaram
    - Ent√£o o modelo prev√™ que este voo tamb√©m atrasar√°
    
    ### Vantagens para Previs√£o de Atrasos:
    - Captura padr√µes locais de atrasos
    - Considera similaridade entre rotas e condi√ß√µes
    - Adapta-se a diferentes regi√µes do espa√ßo de features
    - Decis√µes baseadas em casos reais similares
""")

with st.spinner('Treinando modelo KNN...'):
    y_train_np = y_train.to_numpy()
    
    sample_size = min(100000, int(0.1 * len(X_train)))
    indices = np.random.choice(len(X_train), sample_size, replace=False)
    X_train_sample = X_train[indices]
    y_train_sample = y_train_np[indices]

    knn_param_grid = {
        'n_neighbors': [3, 5],
        'weights': ['uniform'],
        'p': [2]  
    }
    
    knn_grid_search = GridSearchCV(
        KNeighborsClassifier(n_jobs=-1),
        knn_param_grid,
        cv=3,
        scoring={
            'recall': 'recall',
            'precision': 'precision',
            'f1': 'f1'
        },
        refit='recall',
        n_jobs=-1,
        verbose=2
    )
    
    try:
        # 5. Treinamento com dados reduzidos
        knn_grid_search.fit(X_train_sample, y_train_sample)
        knn_model = knn_grid_search.best_estimator_
        knn_pred = knn_model.predict(X_val)
        
    except Exception as e:
        st.error(f"Erro no treinamento: {str(e)}")
        st.stop()

    col1, col2 = st.columns(2)

    with col1:
        # Relat√≥rio de classifica√ß√£o
        report = classification_report(y_val, knn_pred, output_dict=True, zero_division=0)
        df_report = pd.DataFrame(report).transpose()
        
        # Formata√ß√£o da tabela
        df_report = df_report.round(3)
        df_report = df_report.drop('support', axis=1)
        
        # Renomeando √≠ndices
        df_report.index = df_report.index.map({
            '0': 'N√£o Atrasado',
            '1': 'Atrasado',
            'accuracy': 'Acur√°cia',
            'macro avg': 'M√©dia Macro',
            'weighted avg': 'M√©dia Ponderada'
        })
        
        st.write("### Classifica√ß√£o do Modelo:")
        st.dataframe(df_report.style.format("{:.2%}"))
        
        # Melhores par√¢metros
        st.write("### Melhores Par√¢metros:")
        st.json(knn_grid_search.best_params_)

    with col2:
        # Matriz de confus√£o
        st.subheader("üéØ Matriz de Confus√£o")
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(
            confusion_matrix(y_val, knn_pred),
            annot=True,
            fmt="d",
            cmap="Purples",
            ax=ax
        )
        plt.title("KNN - Matriz de Confus√£o")
        plt.xlabel("Previsto")
        plt.ylabel("Real")
        st.pyplot(fig)

#########################################################
###### TREINAMENTO DO MODELO DE ARVORE DE DECISSAO ######
#########################################################

st.subheader("üå≥ Modelo de √°rvore de decis√£o")
st.markdown("""
    ### Por que √Årvore de Decis√£o?
    
    - **Interpretabilidade**: F√°cil visualiza√ß√£o das regras de decis√£o
    - **N√£o-linear**: Captura rela√ß√µes complexas entre features
    - **Robustez**: Lida bem com diferentes tipos de features
    - **Hierarquia**: Identifica features mais importantes
            
    ### Como funciona?
    O modelo cria uma estrutura em √°rvore onde cada n√≥ representa uma decis√£o 
    baseada em uma feature espec√≠fica. Por exemplo:
    - Se a hora de partida < 6h, vai para um caminho
    - Se a dist√¢ncia > 1000 milhas, vai para outro
    - E assim sucessivamente at√© chegar a uma previs√£o final

    ### Vantagens para Previs√£o de Atrasos:
    - Captura naturalmente padr√µes sazonais e hor√°rios
    - Identifica combina√ß√µes cr√≠ticas de fatores que levam a atrasos
    - Permite visualizar o processo de decis√£o
    - Lida bem com features num√©ricas e categ√≥ricas
    - Funciona mesmo com dados n√£o balanceados
""")

with st.spinner('Treinando a √°rvore de decis√£o...'):
    # Convert to numpy array and sample data
    y_train_np = y_train.to_numpy()
    
    sample_size = min(100000, int(0.1 * len(X_train)))
    indices = np.random.choice(len(X_train), sample_size, replace=False)
    X_train_sample = X_train[indices]
    y_train_sample = y_train_np[indices]
    
    param_grid = {
        'max_depth': [5, 10],
        'min_samples_split': [50, 100],
        'min_samples_leaf': [20, 30],
        'criterion': ['gini'],
        'class_weight': [None, 'balanced']
    }

    # Criar e executar GridSearchCV com a amostra
    grid_search = GridSearchCV(
        DecisionTreeClassifier(random_state=42),
        param_grid,
        cv=3,
        scoring={
            'accuracy': 'accuracy',
            'recall': 'recall',
            'precision': 'precision',
            'f1': 'f1'
        },
        refit='recall',  
        n_jobs=-1,
        verbose=1
    )
    
    try:
        # Apply SMOTE on the sample instead of full dataset
        smote = SMOTE(random_state=42)
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_sample, y_train_sample)
        grid_search.fit(X_train_balanced, y_train_balanced)
        
        dt_model = grid_search.best_estimator_
        dt_pred = dt_model.predict(X_val)
        dt_pred_proba = dt_model.predict_proba(X_val)
        
    except Exception as e:
        st.error(f"Erro no treinamento: {str(e)}")
        st.stop()

# Mostrar performance do Decision Tree
col1, col2 = st.columns(2)

with col1:
    # M√©tricas detalhadas
    report = classification_report(y_val, dt_pred, output_dict=True, zero_division=0)
    df_report = pd.DataFrame(report).transpose()
    df_report = df_report.round(3)
    df_report = df_report.drop('support', axis=1)
    
    df_report.index = df_report.index.map({
        '0': 'N√£o Atrasado',
        '1': 'Atrasado',
        'accuracy': 'Acur√°cia',
        'macro avg': 'M√©dia Macro',
        'weighted avg': 'M√©dia Ponderada'
    })
    
    st.write("### Classifica√ß√£o do Modelo:")
    st.dataframe(df_report.style.format("{:.2%}"))
    
    # Melhores par√¢metros
    st.write("### Melhores Par√¢metros:")
    st.json(grid_search.best_params_)

with col2:
    # Matriz de confus√£o
    st.subheader("üéØ Matriz de Confus√£o")
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(
        confusion_matrix(y_val, dt_pred),
        annot=True,
        fmt="d",
        cmap="Greens",
        ax=ax
    )
    plt.title("√Årvore de Decis√£o - Matriz de Confus√£o")
    plt.xlabel("Previsto")
    plt.ylabel("Real")
    st.pyplot(fig)
    
    # Feature Importance
    st.subheader("üîç Import√¢ncia das Features")
    feature_names = (
        numeric_features + 
        [f"{feat}_{val}" for feat, vals in 
         zip(categorical_features, 
             preprocessor.named_transformers_['cat'].categories_) 
         for val in vals[1:]]  # Skip first category due to drop='first'
    )
    
    feature_importance = pd.DataFrame({
        'Feature': feature_names,
        'Importance': dt_model.feature_importances_
    }).sort_values('Importance', ascending=False)
    
    # Plot top 15 most important features
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(
        data=feature_importance.head(15),
        x='Importance',
        y='Feature'
    )
    plt.title("Top 15 Features mais Importantes")
    plt.tight_layout()
    st.pyplot(fig)

#########################################################
################## TENTATIVA DE PREVISAO ################
#########################################################

st.subheader("‚úàÔ∏è Predictor de Atrasos de Voos")

with st.form("flight_predictor"):
    col1, col2 = st.columns(2)
    
    with col1:
        month = st.number_input("M√™s", min_value=1, max_value=12, value=6)
        day = st.number_input("Dia", min_value=1, max_value=31, value=15)
        day_of_week = st.number_input("Dia da Semana (1-7)", min_value=1, max_value=7, value=1)
        dep_hour = st.number_input("Hora de Partida (0-23)", min_value=0, max_value=23, value=14)
        distance = st.number_input("Dist√¢ncia (milhas)", min_value=0, max_value=5000, value=2475)
    
    with col2:
        airline = st.selectbox("Companhia A√©rea", options=sorted(flights['AIRLINE'].unique()))
        origin = st.selectbox("Aeroporto de Origem", options=sorted(flights['ORIGIN_AIRPORT'].unique()))
        destination = st.selectbox("Aeroporto de Destino", options=sorted(flights['DESTINATION_AIRPORT'].unique()))
        cancelled = st.checkbox("Voo Cancelado")
    
    # Adicionar campos para as novas features
    is_weekend = 1 if day_of_week in [6, 7] else 0
    season = pd.cut([month], bins=[0,3,6,9,12], labels=['Winter','Spring','Summer','Fall'])[0]
    time_period = pd.cut([dep_hour], bins=[0,6,12,18,24], labels=['Dawn','Morning','Afternoon','Night'])[0]
    holiday_season = 1 if month in [7,8,12] else 0
    
    model_choice = st.radio(
        "Escolha o Modelo",
        ["√Årvore de Decis√£o", "KNN"]
    )

    submitted = st.form_submit_button("Prever Atraso")

if submitted:
    # Criar DataFrame com todas as features necess√°rias
    input_data = pd.DataFrame([{
        'AIRLINE': airline_encoder.transform([airline])[0],
        'MONTH': month,
        'DAY': day,
        'DAY_OF_WEEK': day_of_week,
        'DEP_HOUR': dep_hour,
        'DISTANCE': distance,
        'CANCELLED': int(cancelled),
        'ORIGIN_ENCODED': origin_encoder.transform([origin])[0],
        'DEST_ENCODED': dest_encoder.transform([destination])[0],
        'IS_WEEKEND': is_weekend,
        'SEASON': season,
        'TIME_PERIOD': time_period,
        'HOLIDAY_SEASON': holiday_season
    }])

    # Preprocessar dados de entrada
    input_processed = preprocessor.transform(input_data)

    # Fazer predi√ß√£o com o modelo escolhido
    if model_choice == "√Årvore de Decis√£o":
        prediction = dt_model.predict(input_processed)[0]
        probability = dt_model.predict_proba(input_processed)[0][1]
    else:  # KNN
        prediction = knn_model.predict(input_processed)[0]
        probability = knn_model.predict_proba(input_processed)[0][1]

    # Mostrar resultados
    result = 'üü• Atrasado' if prediction == 1 else 'üü© No Hor√°rio'
    
    st.markdown(f"### Previs√£o: {result}")
    st.markdown(f"### Probabilidade de Atraso: {probability:.2%}")
    
    if prediction == 1:
        st.warning("Este voo provavelmente ir√° atrasar!")
    else:
        st.success("Este voo provavelmente chegar√° no hor√°rio!")

    # Se for √°rvore de decis√£o, mostrar import√¢ncia das features
    if model_choice == "√Årvore de Decis√£o":
        st.subheader("üîç Import√¢ncia das Features para esta Previs√£o")
        feature_names = (
            numeric_features + 
            [f"{feat}_{val}" for feat, vals in 
             zip(categorical_features, 
                 preprocessor.named_transformers_['cat'].categories_) 
             for val in vals[1:]]
        )
        
        importance = pd.DataFrame({
            'Feature': feature_names,
            'Importance': dt_model.feature_importances_
        }).sort_values('Importance', ascending=False).head(5)
        
        fig, ax = plt.subplots(figsize=(10, 4))
        sns.barplot(data=importance, x='Importance', y='Feature')
        plt.title("Top 5 Features Mais Importantes")
        plt.tight_layout()
        st.pyplot(fig)